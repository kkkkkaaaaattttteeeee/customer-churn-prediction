"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø—Ä–æ–µ–∫—Ç–∞: –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pickle
import os

def main():
    print("=" * 70)
    print("üöÄ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–ï –û–¢–¢–û–ö–ê –ö–õ–ò–ï–ù–¢–û–í - ML –ü–†–û–ï–ö–¢")
    print("=" * 70)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n1. üìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    data_path = "data/raw/telco_churn.csv"
    
    if not os.path.exists(data_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}")
        print("üì• –°–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle:")
        print("   https://www.kaggle.com/datasets/blastchar/telco-customer-churn")
        return
    
    df = pd.read_csv(data_path)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {df.shape[0]} –∫–ª–∏–µ–Ω—Ç–æ–≤, {df.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    # 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    print("\n2. üîß –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•")
    
    # –£–¥–∞–ª—è–µ–º ID
    df = df.drop('customerID', axis=1)
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º TotalCharges
    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–∑–Ω–∞–∫: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ª—É–≥
    service_cols = ['PhoneService', 'InternetService', 'OnlineSecurity', 
                   'OnlineBackup', 'DeviceProtection', 'TechSupport',
                   'StreamingTV', 'StreamingMovies']
    
    def count_services(row):
        count = 0
        for col in service_cols:
            if col in df.columns:
                if str(row[col]) not in ['No', 'No internet service']:
                    count += 1
        return count
    
    df['service_count'] = df.apply(count_services, axis=1)
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    categorical_cols = df.select_dtypes(include=['object']).columns
    
    for col in categorical_cols:
        if col != 'Churn':  # –¶–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].astype(str))
    
    # –ö–æ–¥–∏—Ä—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫: service_count")
    print(f"‚úÖ –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(categorical_cols)-1}")
    
    # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
    print("\n3. üéØ –ü–û–î–ì–û–¢–û–í–ö–ê –î–õ–Ø ML")
    
    X = df.drop('Churn', axis=1)
    y = df['Churn']
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"‚úÖ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} –∫–ª–∏–µ–Ω—Ç–æ–≤")
    print(f"‚úÖ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape[0]} –∫–ª–∏–µ–Ω—Ç–æ–≤")
    print(f"‚úÖ –û—Ç—Ç–æ–∫ –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {y_test.mean()*100:.1f}%")
    
    # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print("\n4. üß† –û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ï–ô")
    
    # –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
    print("\n   üìä –õ–û–ì–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –†–ï–ì–†–ï–°–°–ò–Ø")
    lr_model = LogisticRegression(random_state=42, max_iter=1000)
    lr_model.fit(X_train_scaled, y_train)
    
    y_pred_lr = lr_model.predict(X_test_scaled)
    
    print(f"      Accuracy:  {accuracy_score(y_test, y_pred_lr):.3f}")
    print(f"      Precision: {precision_score(y_test, y_pred_lr):.3f}")
    print(f"      Recall:    {recall_score(y_test, y_pred_lr):.3f}")
    print(f"      F1-Score:  {f1_score(y_test, y_pred_lr):.3f}")
    
    # –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
    print("\n   üå≤ –°–õ–£–ß–ê–ô–ù–´–ô –õ–ï–°")
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    
    y_pred_rf = rf_model.predict(X_test)
    
    print(f"      Accuracy:  {accuracy_score(y_test, y_pred_rf):.3f}")
    print(f"      Precision: {precision_score(y_test, y_pred_rf):.3f}")
    print(f"      Recall:    {recall_score(y_test, y_pred_rf):.3f}")
    print(f"      F1-Score:  {f1_score(y_test, y_pred_rf):.3f}")
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print("\n5. üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    
    os.makedirs('models', exist_ok=True)
    
    with open('models/lr_model.pkl', 'wb') as f:
        pickle.dump(lr_model, f)
    
    with open('models/rf_model.pkl', 'wb') as f:
        pickle.dump(rf_model, f)
    
    with open('models/scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    
    print(f"‚úÖ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ 'models/'")
    
    # 6. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    print("\n6. üìä –°–û–ó–î–ê–ù–ò–ï –û–¢–ß–ï–¢–ê")
    
    os.makedirs('reports', exist_ok=True)
    
    report = f"""
# üìä –û–¢–ß–ï–¢ ML –ü–†–û–ï–ö–¢–ê

## üéØ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤

### üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

**–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è:**
- Accuracy: {accuracy_score(y_test, y_pred_lr):.3f}
- Precision: {precision_score(y_test, y_pred_lr):.3f}
- Recall: {recall_score(y_test, y_pred_lr):.3f}
- F1-Score: {f1_score(y_test, y_pred_lr):.3f}

**–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å:**
- Accuracy: {accuracy_score(y_test, y_pred_rf):.3f}
- Precision: {precision_score(y_test, y_pred_rf):.3f}
- Recall: {recall_score(y_test, y_pred_rf):.3f}
- F1-Score: {f1_score(y_test, y_pred_rf):.3f}

### üìÅ –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
- –ú–æ–¥–µ–ª–∏: `models/lr_model.pkl`, `models/rf_model.pkl`
- Scaler: `models/scaler.pkl`
- –î–∞–Ω–Ω—ã–µ: `data/raw/telco_churn.csv`
- –ö–æ–¥: `main.py`

### üöÄ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: `pip install pandas scikit-learn`
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: `python main.py`
3. –ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã

---
*–ü—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–∞–≤—ã–∫–æ–≤ ML-–∏–Ω–∂–µ–Ω–µ—Ä–∞*
"""
    
    with open('reports/project_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: 'reports/project_report.md'")
    
    # 7. –ò—Ç–æ–≥
    print("\n" + "=" * 70)
    print("üéâ –ü–†–û–ï–ö–¢ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 70)
    
    print(f"\nüìä –ö–õ–Æ–ß–ï–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {df.shape[0]} –∫–ª–∏–µ–Ω—Ç–æ–≤")
    print(f"   ‚Ä¢ –û–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: 2")
    print(f"   ‚Ä¢ –õ—É—á—à–∞—è F1-Score: {max(f1_score(y_test, y_pred_lr), f1_score(y_test, y_pred_rf)):.3f}")
    
    print(f"\nüéØ –ß–¢–û –ü–û–ö–ê–ó–´–í–ê–ï–¢ –ü–†–û–ï–ö–¢:")
    print(f"   ‚Ä¢ –£–º–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
    print(f"   ‚Ä¢ –ù–∞–≤—ã–∫–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ feature engineering")
    print(f"   ‚Ä¢ –û–ø—ã—Ç –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ ML –º–æ–¥–µ–ª–µ–π")
    print(f"   ‚Ä¢ –£–º–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    
    print(f"\nüìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:")
    print(f"   customer-churn-prediction/")
    print(f"   ‚îú‚îÄ‚îÄ data/raw/telco_churn.csv")
    print(f"   ‚îú‚îÄ‚îÄ notebooks/01_data_analysis.ipynb")
    print(f"   ‚îú‚îÄ‚îÄ models/                    # –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
    print(f"   ‚îú‚îÄ‚îÄ reports/                   # –û—Ç—á–µ—Ç—ã")
    print(f"   ‚îú‚îÄ‚îÄ main.py                    # –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç")
    print(f"   ‚îú‚îÄ‚îÄ README.md                  # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è")
    print(f"   ‚îî‚îÄ‚îÄ requirements.txt           # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")

if __name__ == "__main__":
    main()