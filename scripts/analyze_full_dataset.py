"""
–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Telco Customer Churn
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt

def load_and_analyze():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç"""
    print("üîç –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–ê TELCO CUSTOMER CHURN")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data_path = "data/raw/telco_churn.csv"
    
    if not os.path.exists(data_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}")
        return None
    
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {data_path}")
    df = pd.read_csv(data_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–ø–∏—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    df.to_csv("data/processed/churn_data_full.csv", index=False)
    
    return df

def basic_statistics(df):
    """–ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
    print("\nüìä –ë–ê–ó–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print("=" * 70)
    
    print(f"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    
    print(f"\nüìã –°—Ç–æ–ª–±—Ü—ã ({len(df.columns)}):")
    for i, col in enumerate(df.columns, 1):
        print(f"{i:2}. {col}")
    
    print(f"\nüìà –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
    print(df.dtypes)
    
    print(f"\nüîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    missing = df.isnull().sum()
    if missing.sum() == 0:
        print("‚úÖ –ù–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
    else:
        print("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        for col, count in missing[missing > 0].items():
            print(f"  {col}: {count} ({count/len(df)*100:.1f}%)")

def analyze_target(df):
    """–ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
    print("\nüéØ –ê–ù–ê–õ–ò–ó –¶–ï–õ–ï–í–û–ô –ü–ï–†–ï–ú–ï–ù–ù–û–ô (Churn):")
    print("=" * 70)
    
    if 'Churn' not in df.columns:
        print("‚ùå –°—Ç–æ–ª–±–µ—Ü 'Churn' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    churn_counts = df['Churn'].value_counts()
    churn_percent = df['Churn'].value_counts(normalize=True) * 100
    
    print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
    print(f"  No (–±–µ–∑ –æ—Ç—Ç–æ–∫–∞):  {churn_counts['No']:>6} ({churn_percent['No']:5.1f}%)")
    print(f"  Yes (—Å –æ—Ç—Ç–æ–∫–æ–º):  {churn_counts['Yes']:>6} ({churn_percent['Yes']:5.1f}%)")
    
    print(f"\nüìä –î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {churn_percent['Yes']:.1f}% vs {churn_percent['No']:.1f}%")
    print("   -> –ù—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏: Precision, Recall, F1, ROC-AUC")

def analyze_numeric_features(df):
    """–ê–Ω–∞–ª–∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print("\nüî¢ –ê–ù–ê–õ–ò–ó –ß–ò–°–õ–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
    print("=" * 70)
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        print("‚ùå –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    print(f"–ù–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(numeric_cols)}")
    
    for col in numeric_cols:
        print(f"\nüìä {col}:")
        print(f"  Min: {df[col].min():.1f}, Max: {df[col].max():.1f}")
        print(f"  Mean: {df[col].mean():.1f}, Median: {df[col].median():.1f}")
        print(f"  Std: {df[col].std():.1f}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        if df[col].nunique() < 10:
            print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {df[col].nunique()}")
            print(f"  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {df[col].value_counts().to_dict()}")

def analyze_categorical_features(df):
    """–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print("\nüè∑Ô∏è –ê–ù–ê–õ–ò–ó –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
    print("=" * 70)
    
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    if not categorical_cols:
        print("‚ùå –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    print(f"–ù–∞–π–¥–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(categorical_cols)}")
    
    for col in categorical_cols:
        if col != 'customerID':  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º ID
            unique_count = df[col].nunique()
            print(f"\nüìã {col}:")
            print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {unique_count}")
            
            if unique_count <= 10:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–Ω–∞—á–µ–Ω–∏–π
                value_counts = df[col].value_counts()
                for value, count in value_counts.items():
                    percent = (count / len(df)) * 100
                    print(f"  {value}: {count:>5} ({percent:5.1f}%)")

def save_analysis_report(df, report_path="data/processed/analysis_report.txt"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞"""
    print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ß–ï–¢–ê...")
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("–û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –î–ê–ù–ù–´–•: TELCO CUSTOMER CHURN\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n")
        f.write(f"- –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\n")
        f.write(f"- –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {df.isnull().sum().sum()}\n\n")
        
        f.write(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (Churn):\n")
        churn_counts = df['Churn'].value_counts()
        churn_percent = df['Churn'].value_counts(normalize=True) * 100
        f.write(f"- No: {churn_counts['No']} ({churn_percent['No']:.1f}%)\n")
        f.write(f"- Yes: {churn_counts['Yes']} ({churn_percent['Yes']:.1f}%)\n\n")
        
        f.write("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è feature engineering:\n")
        f.write("1. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —á–∏—Å–ª–æ–≤—ã–µ (one-hot encoding)\n")
        f.write("2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å TotalCharges (—Å–µ–π—á–∞—Å —Å—Ç—Ä–æ–∫–∞, —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ–±–µ–ª—ã)\n")
        f.write("3. –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: tenure groups, service count\n")
        f.write("4. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n")
        f.write("5. –£—á–µ—Å—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏\n")
    
    print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –î–ê–ù–ù–´–•")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = load_and_analyze()
    
    if df is None:
        return
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    basic_statistics(df)
    analyze_target(df)
    analyze_numeric_features(df)
    analyze_categorical_features(df)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    save_analysis_report(df)
    
    print("\n" + "=" * 70)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 70)
    
    print("\nüìù –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´:")
    print("1. –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è feature engineering")
    print("2. –ï—Å—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (26.5% churn)")
    print("3. –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print("4. –ú–æ–∂–Ω–æ –ø—Ä–∏—Å—Ç—É–ø–∞—Ç—å –∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—é ML –º–æ–¥–µ–ª–∏")

if __name__ == "__main__":
    main()